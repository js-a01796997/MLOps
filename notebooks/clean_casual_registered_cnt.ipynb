{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae715d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/bike_sharing_cleaned.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a80419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete mixed_type_col\n",
    "df =  df.drop('mixed_type_col', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df881f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NaN values in casual, registered, and cnt columns\n",
    "casual_nan = df['casual'].isna().sum()\n",
    "registered_nan = df['registered'].isna().sum()\n",
    "cnt_nan = df['cnt'].isna().sum()\n",
    "\n",
    "total_rows = len(df)\n",
    "\n",
    "print(f\"NaN values in 'casual': {casual_nan} ({casual_nan/total_rows*100:.2f}%)\")\n",
    "print(f\"NaN values in 'registered': {registered_nan} ({registered_nan/total_rows*100:.2f}%)\")\n",
    "print(f\"NaN values in 'cnt': {cnt_nan} ({cnt_nan/total_rows*100:.2f}%)\")\n",
    "\n",
    "# Sum all NaN values from these 3 columns\n",
    "total_nan = casual_nan + registered_nan + cnt_nan\n",
    "print(f\"\\nTotal NaN values in casual, registered, and cnt: {total_nan} ({total_nan/total_rows*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6030886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values using the relationship: casual + registered = cnt\n",
    "\n",
    "# Fill missing cnt values where casual and registered are available\n",
    "df['cnt'] = df['cnt'].fillna(df['casual'] + df['registered'])\n",
    "\n",
    "# Fill missing casual values where registered and cnt are available\n",
    "df['casual'] = df['casual'].fillna(df['cnt'] - df['registered'])\n",
    "\n",
    "# Fill missing registered values where casual and cnt are available\n",
    "df['registered'] = df['registered'].fillna(df['cnt'] - df['casual'])\n",
    "\n",
    "# Check NaN values after filling\n",
    "casual_nan_after = df['casual'].isna().sum()\n",
    "registered_nan_after = df['registered'].isna().sum()\n",
    "cnt_nan_after = df['cnt'].isna().sum()\n",
    "\n",
    "print(\"After filling missing values:\")\n",
    "print(f\"NaN values in 'casual': {casual_nan_after} ({casual_nan_after/total_rows*100:.2f}%)\")\n",
    "print(f\"NaN values in 'registered': {registered_nan_after} ({registered_nan_after/total_rows*100:.2f}%)\")\n",
    "print(f\"NaN values in 'cnt': {cnt_nan_after} ({cnt_nan_after/total_rows*100:.2f}%)\")\n",
    "\n",
    "total_nan_after = casual_nan_after + registered_nan_after + cnt_nan_after\n",
    "print(f\"\\nTotal NaN values after filling: {total_nan_after} ({total_nan_after/total_rows*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c76b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with NaN values in casual, registered, or cnt columns\n",
    "rows_before = len(df)\n",
    "df = df.dropna(subset=['casual', 'registered', 'cnt'])\n",
    "rows_after = len(df)\n",
    "\n",
    "rows_deleted = rows_before - rows_after\n",
    "print(f\"Rows before deletion: {rows_before}\")\n",
    "print(f\"Rows after deletion: {rows_after}\")\n",
    "print(f\"Rows deleted: {rows_deleted} ({rows_deleted/rows_before*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahlhoh9rb2h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pattern of negative values\n",
    "print(\"=\"*80)\n",
    "print(\"ROUNDING VALUES TO INTEGERS\")\n",
    "print(\"=\"*80)\n",
    "print(\"All values in casual, registered, and cnt have been rounded to integers\\n\")\n",
    "\n",
    "df['casual'] = df['casual'].round().astype(int)\n",
    "df['registered'] = df['registered'].round().astype(int)\n",
    "df['cnt'] = df['cnt'].round().astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYZING NEGATIVE VALUES PATTERN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "negative_mask = (df['casual'] < 0) | (df['registered'] < 0) | (df['cnt'] < 0)\n",
    "negative_rows = df[negative_mask].copy()\n",
    "\n",
    "if len(negative_rows) > 0:\n",
    "    # Count how many negative values in each row\n",
    "    negative_rows['neg_count'] = (\n",
    "        (negative_rows['casual'] < 0).astype(int) + \n",
    "        (negative_rows['registered'] < 0).astype(int) + \n",
    "        (negative_rows['cnt'] < 0).astype(int)\n",
    "    )\n",
    "    \n",
    "    rows_with_1_neg = (negative_rows['neg_count'] == 1).sum()\n",
    "    rows_with_2_neg = (negative_rows['neg_count'] == 2).sum()\n",
    "    rows_with_3_neg = (negative_rows['neg_count'] == 3).sum()\n",
    "    \n",
    "    print(f\"Total rows with negative values: {len(negative_rows)}\")\n",
    "    print(f\"\\nBreakdown:\")\n",
    "    print(f\"  Rows with 1 negative value: {rows_with_1_neg}\")\n",
    "    print(f\"  Rows with 2 negative values: {rows_with_2_neg}\")\n",
    "    print(f\"  Rows with 3 negative values: {rows_with_3_neg}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ROWS WITH NEGATIVE VALUES\")\n",
    "    print(\"=\"*80)\n",
    "    display(negative_rows[['instant', 'dteday', 'casual', 'registered', 'cnt', 'neg_count']].sort_values('neg_count', ascending=False))\n",
    "else:\n",
    "    print(\"No negative values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "khjjla9pei",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate rows with negative values (since all have only 1 negative per row)\n",
    "print(\"=\"*80)\n",
    "print(\"RECALCULATING NEGATIVE VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For rows with negative casual: recalculate casual = cnt - registered\n",
    "negative_casual_mask = df['casual'] < 0\n",
    "if negative_casual_mask.sum() > 0:\n",
    "    print(f\"Recalculating {negative_casual_mask.sum()} rows with negative casual values...\")\n",
    "    df.loc[negative_casual_mask, 'casual'] = df.loc[negative_casual_mask, 'cnt'] - df.loc[negative_casual_mask, 'registered']\n",
    "\n",
    "# For rows with negative registered: recalculate registered = cnt - casual\n",
    "negative_registered_mask = df['registered'] < 0\n",
    "if negative_registered_mask.sum() > 0:\n",
    "    print(f\"Recalculating {negative_registered_mask.sum()} rows with negative registered values...\")\n",
    "    df.loc[negative_registered_mask, 'registered'] = df.loc[negative_registered_mask, 'cnt'] - df.loc[negative_registered_mask, 'casual']\n",
    "\n",
    "# For rows with negative cnt: recalculate cnt = casual + registered\n",
    "negative_cnt_mask = df['cnt'] < 0\n",
    "if negative_cnt_mask.sum() > 0:\n",
    "    print(f\"Recalculating {negative_cnt_mask.sum()} rows with negative cnt values...\")\n",
    "    df.loc[negative_cnt_mask, 'cnt'] = df.loc[negative_cnt_mask, 'casual'] + df.loc[negative_cnt_mask, 'registered']\n",
    "\n",
    "# Verify no negative values remain\n",
    "print(\"\\nVerification after recalculation:\")\n",
    "print(f\"  Negative casual: {(df['casual'] < 0).sum()}\")\n",
    "print(f\"  Negative registered: {(df['registered'] < 0).sum()}\")\n",
    "print(f\"  Negative cnt: {(df['cnt'] < 0).sum()}\")\n",
    "\n",
    "if (df['casual'] < 0).sum() == 0 and (df['registered'] < 0).sum() == 0 and (df['cnt'] < 0).sum() == 0:\n",
    "    print(\"\\n All negative values successfully recalculated!\")\n",
    "else:\n",
    "    print(\"\\n Warning: Some negative values remain!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0w0hwq949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with remaining negative values\n",
    "print(\"=\"*80)\n",
    "print(\"DELETING ROWS WITH NEGATIVE VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rows_before = len(df)\n",
    "\n",
    "# Create mask for rows with any negative value\n",
    "negative_mask = (df['casual'] < 0) | (df['registered'] < 0) | (df['cnt'] < 0)\n",
    "rows_with_negatives = negative_mask.sum()\n",
    "\n",
    "# Drop rows with negative values\n",
    "df = df[~negative_mask]\n",
    "\n",
    "rows_after = len(df)\n",
    "rows_deleted = rows_before - rows_after\n",
    "\n",
    "print(f\"Rows before deletion: {rows_before}\")\n",
    "print(f\"Rows after deletion: {rows_after}\")\n",
    "print(f\"Rows deleted: {rows_deleted} ({rows_deleted/rows_before*100:.2f}%)\")\n",
    "\n",
    "# Verify no negative values remain\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"  Negative casual: {(df['casual'] < 0).sum()}\")\n",
    "print(f\"  Negative registered: {(df['registered'] < 0).sum()}\")\n",
    "print(f\"  Negative cnt: {(df['cnt'] < 0).sum()}\")\n",
    "print(\"\\n All rows with negative values have been deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5i9l14ejsdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate rows where casual + registered != cnt\n",
    "print(\"=\"*80)\n",
    "print(\"FIXING INCONSISTENT ROWS (casual + registered != cnt)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find inconsistent rows (using integer comparison, no tolerance needed)\n",
    "inconsistent_mask = (df['casual'] + df['registered']) != df['cnt']\n",
    "inconsistent_count = inconsistent_mask.sum()\n",
    "\n",
    "print(f\"Rows where casual + registered != cnt: {inconsistent_count} ({inconsistent_count/len(df)*100:.2f}%)\")\n",
    "\n",
    "if inconsistent_count > 0:\n",
    "    print(f\"\\nRecalculating cnt = casual + registered for {inconsistent_count} rows...\")\n",
    "    \n",
    "    # Recalculate cnt as the sum of casual and registered\n",
    "    df.loc[inconsistent_mask, 'cnt'] = df.loc[inconsistent_mask, 'casual'] + df.loc[inconsistent_mask, 'registered']\n",
    "    \n",
    "    # Verify all rows are now consistent\n",
    "    still_inconsistent = ((df['casual'] + df['registered']) != df['cnt']).sum()\n",
    "    \n",
    "    print(\"\\nVerification after recalculation:\")\n",
    "    print(f\"  Inconsistent rows remaining: {still_inconsistent}\")\n",
    "    \n",
    "    if still_inconsistent == 0:\n",
    "        print(\"\\n All rows now follow the relationship: casual + registered = cnt\")\n",
    "    else:\n",
    "        print(\"\\n Warning: Some inconsistent rows remain!\")\n",
    "else:\n",
    "    print(\"\\n All rows already follow the relationship: casual + registered = cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect outliers using IQR method\n",
    "def detect_outliers(df, column_name, iqr_multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Detect outliers in a column using the IQR method.\n",
    "    Returns the index of outlier rows.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "    - column_name: Column to analyze\n",
    "    - iqr_multiplier: Multiplier for IQR (default=1.5)\n",
    "    \"\"\"\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    \n",
    "    outlier_mask = (df[column_name] < lower_bound) | (df[column_name] > upper_bound)\n",
    "    outlier_indices = df[outlier_mask].index\n",
    "    \n",
    "    print(f\"\\nColumn: {column_name} (IQR multiplier: {iqr_multiplier})\")\n",
    "    print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "    print(f\"  Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
    "    print(f\"  Number of outliers: {len(outlier_indices)} ({len(outlier_indices)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    return outlier_indices\n",
    "\n",
    "\n",
    "IQR_MULTIPLIER = 2.5\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"OUTLIER DETECTION (IQR Multiplier: {IQR_MULTIPLIER})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "casual_outliers = detect_outliers(df, 'casual', IQR_MULTIPLIER)\n",
    "registered_outliers = detect_outliers(df, 'registered', IQR_MULTIPLIER)\n",
    "cnt_outliers = detect_outliers(df, 'cnt', IQR_MULTIPLIER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b77e373",
   "metadata": {},
   "source": [
    "## Outlier Detection Strategy\n",
    "\n",
    "I am using an IQR multiplier of **2.5** instead of the standard 1.5 to detect more extreme outliers only. \n",
    "\n",
    "**Rationale:**\n",
    "- Outliers in bike sharing data could be legitimate due to holidays, special events, or favorable weather conditions\n",
    "- Using a higher threshold (2.5) helps avoid flagging legitimate high-demand periods as outliers\n",
    "- This approach focuses on identifying truly anomalous data points that are likely data entry errors rather than natural variations in demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gzhvm8zzv44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows where outliers appear in only one column\n",
    "casual_only = set(casual_outliers) - set(registered_outliers) - set(cnt_outliers)\n",
    "registered_only = set(registered_outliers) - set(casual_outliers) - set(cnt_outliers)\n",
    "cnt_only = set(cnt_outliers) - set(casual_outliers) - set(registered_outliers)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUTLIERS IN SINGLE COLUMNS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Outliers only in 'casual': {len(casual_only)}\")\n",
    "print(f\"Outliers only in 'registered': {len(registered_only)}\")\n",
    "print(f\"Outliers only in 'cnt': {len(cnt_only)}\")\n",
    "\n",
    "# Recalculate values for rows with outliers in only one column\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECALCULATING VALUES FOR SINGLE-COLUMN OUTLIERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For casual outliers only: recalculate casual = cnt - registered\n",
    "for idx in casual_only:\n",
    "    old_casual = df.loc[idx, 'casual']\n",
    "    df.loc[idx, 'casual'] = df.loc[idx, 'cnt'] - df.loc[idx, 'registered']\n",
    "    new_casual = df.loc[idx, 'casual']\n",
    "    if abs(old_casual - new_casual) > 0.01:\n",
    "        print(f\"Row {idx}: casual changed from {old_casual:.2f} to {new_casual:.2f}\")\n",
    "\n",
    "# For registered outliers only: recalculate registered = cnt - casual\n",
    "for idx in registered_only:\n",
    "    old_registered = df.loc[idx, 'registered']\n",
    "    df.loc[idx, 'registered'] = df.loc[idx, 'cnt'] - df.loc[idx, 'casual']\n",
    "    new_registered = df.loc[idx, 'registered']\n",
    "    if abs(old_registered - new_registered) > 0.01:\n",
    "        print(f\"Row {idx}: registered changed from {old_registered:.2f} to {new_registered:.2f}\")\n",
    "\n",
    "# For cnt outliers only: recalculate cnt = casual + registered\n",
    "for idx in cnt_only:\n",
    "    old_cnt = df.loc[idx, 'cnt']\n",
    "    df.loc[idx, 'cnt'] = df.loc[idx, 'casual'] + df.loc[idx, 'registered']\n",
    "    new_cnt = df.loc[idx, 'cnt']\n",
    "    if abs(old_cnt - new_cnt) > 0.01:\n",
    "        print(f\"Row {idx}: cnt changed from {old_cnt:.2f} to {new_cnt:.2f}\")\n",
    "\n",
    "print(f\"\\nTotal values recalculated: {len(casual_only) + len(registered_only) + len(cnt_only)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5mhhtqjw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with outliers in 2 or more columns\n",
    "all_indices = set(casual_outliers) | set(registered_outliers) | set(cnt_outliers)\n",
    "\n",
    "multi_outlier_rows = []\n",
    "for idx in all_indices:\n",
    "    outlier_count = 0\n",
    "    outlier_cols = []\n",
    "    \n",
    "    if idx in casual_outliers:\n",
    "        outlier_count += 1\n",
    "        outlier_cols.append('casual')\n",
    "    if idx in registered_outliers:\n",
    "        outlier_count += 1\n",
    "        outlier_cols.append('registered')\n",
    "    if idx in cnt_outliers:\n",
    "        outlier_count += 1\n",
    "        outlier_cols.append('cnt')\n",
    "    \n",
    "    if outlier_count >= 2:\n",
    "        multi_outlier_rows.append((idx, outlier_count, outlier_cols))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ROWS WITH OUTLIERS IN 2 OR MORE COLUMNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(multi_outlier_rows) > 0:\n",
    "    # Sort by number of outlier columns (descending)\n",
    "    multi_outlier_rows.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    outliers_in_3 = sum(1 for _, count, _ in multi_outlier_rows if count == 3)\n",
    "    outliers_in_2 = sum(1 for _, count, _ in multi_outlier_rows if count == 2)\n",
    "    total_multi_outliers = outliers_in_3 + outliers_in_2\n",
    "    \n",
    "    print(f\"Total rows with outliers in 2 or more columns: {total_multi_outliers} ({total_multi_outliers/len(df)*100:.2f}%)\")\n",
    "    print(\"\\nBreakdown:\")\n",
    "    print(f\"  Outliers in all 3 columns: {outliers_in_3} ({outliers_in_3/len(df)*100:.2f}%)\")\n",
    "    print(f\"  Outliers in exactly 2 columns: {outliers_in_2} ({outliers_in_2/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Show the actual rows\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED VIEW OF ROWS WITH MULTIPLE OUTLIERS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    multi_outlier_indices = [idx for idx, _, _ in multi_outlier_rows]\n",
    "    result_df = df.loc[multi_outlier_indices].copy()\n",
    "    result_df['outlier_columns'] = [', '.join(cols) for _, _, cols in multi_outlier_rows]\n",
    "    result_df['outlier_count'] = [count for _, count, _ in multi_outlier_rows]\n",
    "    \n",
    "    # Display relevant columns\n",
    "    display_cols = ['instant', 'dteday', 'casual', 'registered', 'cnt', 'outlier_count', 'outlier_columns']\n",
    "    display(result_df[display_cols].head())\n",
    "else:\n",
    "    print(\"No rows found with outliers in 2 or more columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with outliers in 2 or more columns\n",
    "rows_before_delete = len(df)\n",
    "\n",
    "# Get indices of rows with multiple outliers\n",
    "multi_outlier_indices = [idx for idx, _, _ in multi_outlier_rows]\n",
    "\n",
    "# Drop these rows from the dataframe\n",
    "df = df.drop(index=multi_outlier_indices)\n",
    "\n",
    "rows_after_delete = len(df)\n",
    "rows_deleted_outliers = rows_before_delete - rows_after_delete\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DELETING ROWS WITH OUTLIERS IN 2 OR MORE COLUMNS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Rows before deletion: {rows_before_delete}\")\n",
    "print(f\"Rows after deletion: {rows_after_delete}\")\n",
    "print(f\"Rows deleted: {rows_deleted_outliers} ({rows_deleted_outliers/rows_before_delete*100:.2f}%)\")\n",
    "print(f\"\\nRemaining rows: {rows_after_delete}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac029eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../data/processed/bike_sharing_cleaned.csv\", index=False)\n",
    "# print(\"Data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993b89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
